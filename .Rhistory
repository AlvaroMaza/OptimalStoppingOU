training_length <- start + 200
# Extract training and testing data
training_data <- OU_path[start + 1:(training_length - start)]
testing_data <- OU_path[(training_length + 1):(training_length + testing_length)]
# Infer the boundary using the training data
inferred_results <- infer_boundary_gold_silver(training_data, delta = 1/252, z_alpha = 0.1, partition_length = testing_length)
#print(inferred_results$boundary_est)
# Define the split index
split_index <- training_length
# Create a filename for each plot
plot_filename <- paste0("boundary_plot_", start, ".pdf")
# Open a PDF device
pdf(plot_filename)
# Plot the boundary
plot_boundary_gold_silver(OU_path, inferred_results, split_index, date_line)
# Close the PDF device
dev.off()
# Check the relationship between the first testing data point and the inferred boundary
initial_test_value <- testing_data[1]
initial_boundary_value <- inferred_results$boundary_est[1]
if (initial_test_value > initial_boundary_value) {
# Strategy 1: Exit on Crossing
for (i in 1:length(testing_data)) {
if (testing_data[i] < inferred_results$boundary_est[i]) {
profit_crossing <- inferred_results$est_theta$mu - inferred_results$boundary_est[i]
total_profit_crossing <- total_profit_crossing + profit_crossing
break
}
}
# Strategy 2: Exit on Crossing lower bound
for (i in 1:length(testing_data)) {
if (testing_data[i] < inferred_results$lower_bound[i]) {
profit_crossing_lower <- inferred_results$est_theta$mu - inferred_results$lower_bound[i]
total_profit_crossing_lower_bound <- total_profit_crossing_lower_bound + profit_crossing_lower
break
}
}
# Strategy 3: Hold Until Expiration
last_test_value <- testing_data[length(testing_data)]
profit_expiration <- max(0,inferred_results$est_theta$mu - last_test_value)
total_profit_expiration <- total_profit_expiration + profit_expiration
}
}
# Loop to update start variable and plot results
for (start in seq(0, length(OU_path) - 260, by = testing_length)) {
# Define training and testing length
training_length <- start + 200
# Extract training and testing data
training_data <- OU_path[start + 1:(training_length - start)]
testing_data <- OU_path[(training_length + 1):(training_length + testing_length)]
# Infer the boundary using the training data
inferred_results <- infer_boundary_gold_silver(training_data, delta = 1/252, z_alpha = 0.1, partition_length = testing_length)
#print(inferred_results$boundary_est)
# Define the split index
split_index <- training_length
# Create a filename for each plot
plot_filename <- paste0("boundary_plot_", start, ".pdf")
# Open a PDF device
pdf(plot_filename, width = 12, height = 7)
# Plot the boundary
plot_boundary_gold_silver(OU_path, inferred_results, split_index, date_line)
# Close the PDF device
dev.off()
# Check the relationship between the first testing data point and the inferred boundary
initial_test_value <- testing_data[1]
initial_boundary_value <- inferred_results$boundary_est[1]
if (initial_test_value > initial_boundary_value) {
# Strategy 1: Exit on Crossing
for (i in 1:length(testing_data)) {
if (testing_data[i] < inferred_results$boundary_est[i]) {
profit_crossing <- inferred_results$est_theta$mu - inferred_results$boundary_est[i]
total_profit_crossing <- total_profit_crossing + profit_crossing
break
}
}
# Strategy 2: Exit on Crossing lower bound
for (i in 1:length(testing_data)) {
if (testing_data[i] < inferred_results$lower_bound[i]) {
profit_crossing_lower <- inferred_results$est_theta$mu - inferred_results$lower_bound[i]
total_profit_crossing_lower_bound <- total_profit_crossing_lower_bound + profit_crossing_lower
break
}
}
# Strategy 3: Hold Until Expiration
last_test_value <- testing_data[length(testing_data)]
profit_expiration <- max(0,inferred_results$est_theta$mu - last_test_value)
total_profit_expiration <- total_profit_expiration + profit_expiration
}
}
# Function to plot the inferred boundary
plot_boundary_gold_silver <- function(data, inferred_results, split_index, date_line) {
# Plot the data up to the split point
plot(date_line[1:split_index], as.numeric(data[1:split_index]), type = "l", col = "black",
xlim = range(date_line), ylim = range(c(min(data), max(data))),
xlab = "Date", ylab = "Value")
# Add the data after the split as a dotted line
lines(date_line[(split_index + 1):length(data)], data[(split_index + 1):length(data)], col = "black", lty = 2)
# Add the inferred boundary estimates and confidence intervals
boundary_dates <- date_line[split_index:(split_index + length(inferred_results$boundary_est) - 1)]
lines(boundary_dates, inferred_results$boundary_est, col = "blue", lwd = 2)
lines(boundary_dates, inferred_results$upper_bound, col = "blue", lty = 2)
lines(boundary_dates, inferred_results$lower_bound, col = "blue", lty = 2)
# Add a shaded area for the confidence interval (optional)
polygon(c(boundary_dates, rev(boundary_dates)),
c(inferred_results$upper_bound, rev(inferred_results$lower_bound)),
col = rgb(0, 0, 1, 0.2), border = NA)
# Add a vertical line at the split point
abline(v = date_line[split_index], col = "black", lwd = 1)
# Add the shaded area from the 400th observation to the split point
shade_start <- split_index - 200
rect(xleft = date_line[shade_start + 1], ybottom = min(data),
xright = date_line[split_index], ytop = max(data),
col = rgb(0.6, 0.6, 1, 0.2), border = NA)
}
# Initialize variables to accumulate total profits for each strategy
total_profit_crossing <- 0
#total_profit_crossing_upper_bound <- 0
total_profit_crossing_lower_bound <- 0
total_profit_expiration <- 0
testing_length <- 60
# Loop to update start variable and plot results
for (start in seq(0, length(OU_path) - 260, by = testing_length)) {
# Define training and testing length
training_length <- start + 200
# Extract training and testing data
training_data <- OU_path[start + 1:(training_length - start)]
testing_data <- OU_path[(training_length + 1):(training_length + testing_length)]
# Infer the boundary using the training data
inferred_results <- infer_boundary_gold_silver(training_data, delta = 1/252, z_alpha = 0.1, partition_length = testing_length)
#print(inferred_results$boundary_est)
# Define the split index
split_index <- training_length
# Create a filename for each plot
plot_filename <- paste0("gold_silver_", start, ".pdf")
# Open a PDF device
pdf(plot_filename, width = 12, height = 7)
# Plot the boundary
plot_boundary_gold_silver(OU_path, inferred_results, split_index, date_line)
# Close the PDF device
dev.off()
# Check the relationship between the first testing data point and the inferred boundary
initial_test_value <- testing_data[1]
initial_boundary_value <- inferred_results$boundary_est[1]
if (initial_test_value > initial_boundary_value) {
# Strategy 1: Exit on Crossing
for (i in 1:length(testing_data)) {
if (testing_data[i] < inferred_results$boundary_est[i]) {
profit_crossing <- inferred_results$est_theta$mu - inferred_results$boundary_est[i]
total_profit_crossing <- total_profit_crossing + profit_crossing
break
}
}
# Strategy 2: Exit on Crossing lower bound
for (i in 1:length(testing_data)) {
if (testing_data[i] < inferred_results$lower_bound[i]) {
profit_crossing_lower <- inferred_results$est_theta$mu - inferred_results$lower_bound[i]
total_profit_crossing_lower_bound <- total_profit_crossing_lower_bound + profit_crossing_lower
break
}
}
# Strategy 3: Hold Until Expiration
last_test_value <- testing_data[length(testing_data)]
profit_expiration <- max(0,inferred_results$est_theta$mu - last_test_value)
total_profit_expiration <- total_profit_expiration + profit_expiration
}
}
cat("Total Profit from Exit on Crossing:", total_profit_crossing, "\n")
cat("Total Profit from Exit on Crossing Lower Bound:", total_profit_crossing_lower_bound, "\n")
cat("Total Profit from Holding Until Expiration:", total_profit_expiration, "\n")
# Function to plot the boundary with time as the x-axis
plot_boundary <- function(data, inferred_results, actual_boundary, split_index, timestep) {
# Calculate time points
time_points <- (0:(length(data) - 1)) * timestep
split_time <- split_index * timestep
# Create a plotting device with time as the x-axis
plot(time_points[1:split_index], as.numeric(data[1:split_index]), type = "l", col = "black",
xlim = c(0, max(time_points)), ylim = range(c(14, max(data))),
xlab = "Time", ylab = "Value")
# Add the data after the split as a dotted line
lines(time_points[(split_index + 1):length(data)], data[(split_index + 1):length(data)], col = "black", lty = 2)
# Add the inferred boundary estimates and confidence intervals
lines(time_points[split_index:(split_index + length(inferred_results$boundary_est) - 1)],
inferred_results$boundary_est, col = "blue", lwd = 2)
lines(time_points[split_index:(split_index + length(inferred_results$upper_bound) - 1)],
inferred_results$upper_bound, col = "blue", lty = 2)
lines(time_points[split_index:(split_index + length(inferred_results$lower_bound) - 1)],
inferred_results$lower_bound, col = "blue", lty = 2)
# Add a shaded area for the confidence interval
polygon(c(time_points[split_index:(split_index + length(inferred_results$boundary_est) - 1)],
rev(time_points[split_index:(split_index + length(inferred_results$boundary_est) - 1)])),
c(inferred_results$upper_bound, rev(inferred_results$lower_bound)), col = rgb(0, 0, 1, 0.2), border = NA)
# Plot the actual boundary for comparison
lines(time_points[split_index:(split_index + length(actual_boundary) - 1)], actual_boundary, col = "red", lty = 1)
# Add a vertical line at the split point
abline(v = split_time, col = "black", lwd = 1)
}
# Load the specified file index
file_index <- 1  # Replace with the desired file index
folder_name <- "rds_files"
# Define file paths
x_path_file <- file.path(folder_name, paste0("X_path_", file_index, ".rds"))
inferred_boundary_file <- file.path(folder_name, paste0("inferred_boundary_", file_index, ".rds"))
# Load the data from the .rds files
data <- readRDS(x_path_file)
inferred_results <- readRDS(inferred_boundary_file)
# Define the split index and timestep
split_index <- 400  # Assuming the split is always at 400 points
timestep <- 0.01
# Define the actual boundary
actual_boundary <- boundary_wrapper(c(alpha = 3, mu = 20, sigma2 = 2), partition_length = 100, strike = 19.5, expiration = 1)
plot_boundary(data, inferred_results, actual_boundary, split_index, timestep)
# Function to compute proportions of non-inclusions from saved .rds files
compute_proportions_from_files <- function(M = 100) {
folder_name <- "rds_files"
# Initialize vectors to store results
non_inclusions_list <- vector("list", M)
real_boundary <- boundary_wrapper(c(alpha = 3, mu = 20, sigma2 = 2), partition_length = 100, strike = 19.5, expiration = 1)
# Loop through each trial index
for (trial_index in 1:M) {
x_sample_file <- file.path(folder_name, paste0("X_path_", trial_index, ".rds"))
inferred_boundary_file <- file.path(folder_name, paste0("inferred_boundary_", trial_index, ".rds"))
# Load the data
X_sample <- readRDS(x_sample_file)
inferred_results <- readRDS(inferred_boundary_file)
# Calculate non-inclusion points
non_inclusions <- integer(length(real_boundary))
for (j in 1:length(real_boundary)) {
if (real_boundary[j] < inferred_results$lower_bound[j] || real_boundary[j] > inferred_results$upper_bound[j]) {
non_inclusions[j] <- 1
}
}
# Store the results
non_inclusions_list[[trial_index]] <- non_inclusions
}
# Compute proportions
proportions <- Reduce("+", non_inclusions_list) / M
# Define time points (scaled to range from 0 to 1)
timestep <- 0.01
time_points <- (0:(length(proportions) - 1)) * timestep
time_points_scaled <- time_points / max(time_points)
return(list(proportions = proportions, time_points_scaled = time_points_scaled))
}
# Set parameters
M <- 200
# Compute proportions from saved files
results <- compute_proportions_from_files(M = M)
proportions <- results$proportions
time_points_scaled <- results$time_points_scaled
# Define alpha and calculate q_alpha
alpha <- 0.1
q_alpha <- qnorm(1 - alpha / 2)
# Calculate dotted lines values (scaled to range from 0 to 1)
dotted_lines <- alpha + c(-1, 1) * q_alpha * sqrt(alpha * (1 - alpha) / M)
# Plot proportions
plot(time_points_scaled, proportions, type = "l", col = "red", xlim = c(0, 1), ylim = c(0, 0.4),
xlab = "Time", ylab = "Proportion of Non-inclusions")
# Add dashed line for alpha
abline(h = alpha, col = "black", lty = 2)
# Add dotted lines
abline(h = dotted_lines, col = "black", lty = 3)
# Close the PDF device
dev.off()
# Function to estimate parameters from saved paths
parameter_estimation_table_from_rds <- function(file_paths, delta = 0.01) {
sample_size <- length(file_paths)
results <- data.frame(alpha = numeric(sample_size),
mu = numeric(sample_size),
sigma2 = numeric(sample_size))
for (i in 1:sample_size) {
# Load the sample path from the .rds file
X <- readRDS(file_paths[i])
# Estimate the parameters using the est_OU function
result <- est_OU(X, delta)
# Store the estimates in the data frame
results[i,] <- c(result$alpha, result$mu, result$sigma2)
}
return(results)
}
# Example usage: specify the path where your .rds files are stored
folder_name <- "rds_files" # Folder containing .rds files
file_paths <- list.files(path = folder_name, pattern = "X_path_.*\\.rds", full.names = TRUE)
# Estimate parameters using the saved paths
results <- parameter_estimation_table_from_rds(file_paths, delta = 0.01)
# Calculate statistics
means <- colMeans(results)
medians <- apply(results, 2, median)
sds <- apply(results, 2, sd)
# Print results
cat("Mean of alpha: ", means['alpha'], "\n")
cat("Median of alpha: ", medians['alpha'], "\n")
cat("Standard deviation of alpha: ", sds['alpha'], "\n\n")
cat("Mean of mu: ", means['mu'], "\n")
cat("Median of mu: ", medians['mu'], "\n")
cat("Standard deviation of mu: ", sds['mu'], "\n\n")
cat("Mean of sigma2: ", means['sigma2'], "\n")
cat("Median of sigma2: ", medians['sigma2'], "\n")
cat("Standard deviation of sigma2: ", sds['sigma2'], "\n")
if (!dir.exists("scenario_plots")) {
dir.create("scenario_plots")
}
# Save the alpha density plot as a PDF
pdf("scenario_plots/alpha_density_plot.pdf", width = 12, height = 7)
ggplot(results, aes(x = alpha)) +
geom_density(fill = "lightblue", color = "black", alpha = 0.7) +
geom_vline(xintercept = 1, color = "red", linetype = "dashed", size = 1) +
xlab(expression(hat(alpha))) + ylab("Density")
dev.off()
# Save the mu density plot as a PDF
pdf("scenario_plots/mu_density_plot.pdf", width = 12, height = 7)
ggplot(results, aes(x = mu)) +
geom_density(fill = "lightblue", color = "black", alpha = 0.7) +
geom_vline(xintercept = 20, color = "red", linetype = "dashed", size = 1) +
xlab(expression(hat(mu))) + ylab("Density")
dev.off()
# Save the sigma2 density plot as a PDF
pdf("scenario_plots/sigma2_density_plot.pdf", width = 12, height = 7)
ggplot(results, aes(x = sigma2)) +
geom_density(fill = "lightblue", color = "black", alpha = 0.7) +
geom_vline(xintercept = 2, color = "red", linetype = "dashed", size = 1) +
xlab(expression(hat(sigma)^2)) + ylab("Density")
dev.off()
check_convergence <- function(file_paths, mu, sigma2, alpha, T = 4, delta = 0.01, alpha_level = 0.05) {
n <- T / delta
theta <- c(alpha, mu, sigma2)
K <- length(theta)
chi_squared_stats <- numeric(length(file_paths))
vectors <- matrix(NA, nrow = length(file_paths), ncol = K)
for (i in 1:length(file_paths)) {
X <- readRDS(file_paths[i])[1:400]
result <- est_OU(X, delta)
fisher_info <- fisher_info_second_derivatives(result$alpha, result$mu, result$sigma2, X, delta,
d2_logL_dalpha2, d2_logL_dmu2, d2_logL_dsigma2,
d2_logL_dalphadmu, d2_logL_dalphadsigma, d2_logL_dmudsigma)
R <- chol(fisher_info)
z <- sqrt(n) * (R %*% (c(result$alpha, result$mu, result$sigma2) - theta))
chi_squared_stats[i] <- sum(z^2)
vectors[i, ] <- z
}
chi_squared_critical_value <- qchisq(1 - alpha_level, df = K)
coverage_probability <- mean(chi_squared_stats <= chi_squared_critical_value)
return(list(vectors = vectors, chi_squared_stats = chi_squared_stats,
critical_value = chi_squared_critical_value,
coverage_probability = coverage_probability))
}
# Define the parameters
M <- 200
mu <- 20
sigma2 <- 1
alpha <- 3
T <- 4
delta <- 0.01
alpha_level <- 0.1
# List all paths to the rds files
file_paths <- list.files("rds_files", pattern = "X_path_.*\\.rds", full.names = TRUE)
# Check convergence using pre-generated data and specified parameters
convergence_results <- check_convergence(file_paths, mu, sigma2, alpha, T, delta, alpha_level)
coverage_probability <- convergence_results$coverage_probability
vectors <- convergence_results$vectors
critical_value <- convergence_results$critical_value
chi_squared_stats <- convergence_results$chi_squared_stats
# Calculate the critical radius
critical_radius <- sqrt(critical_value)
# Function to generate sphere coordinates
generate_sphere <- function(radius, n = 100) {
theta <- seq(0, 2 * pi, length.out = n)
phi <- seq(0, pi, length.out = n)
theta_grid <- rep(theta, each = length(phi))
phi_grid <- rep(phi, length(theta))
x <- radius * sin(phi_grid) * cos(theta_grid)
y <- radius * sin(phi_grid) * sin(theta_grid)
z <- radius * cos(phi_grid)
return(list(x = x, y = y, z = z))
}
# Generate sphere coordinates
sphere_coords <- generate_sphere(critical_radius)
# Create a 3D scatter plot with Plotly
fig <- plot_ly(x = vectors[,1], y = vectors[,2], z = vectors[,3],
type = 'scatter3d', mode = 'markers',
marker = list(color = ifelse(chi_squared_stats > critical_value, 'red', 'blue'),
size = 3)) %>%
add_trace(x = sphere_coords$x, y = sphere_coords$y, z = sphere_coords$z,
type = 'scatter3d', mode = 'markers',
marker = list(color = 'lightblue', size = 2, opacity = 0.3),
showlegend = FALSE) %>%
layout(scene = list(xaxis = list(title = 'Z1'),
yaxis = list(title = 'Z2'),
zaxis = list(title = 'Z3')))
# Show the plot
fig
sigma2 <- 2
alpha <- 3
T <- 4
delta <- 0.01
alpha_level <- 0.1
# List all paths to the rds files
file_paths <- list.files("rds_files", pattern = "X_path_.*\\.rds", full.names = TRUE)
# Check convergence using pre-generated data and specified parameters
convergence_results <- check_convergence(file_paths, mu, sigma2, alpha, T, delta, alpha_level)
coverage_probability <- convergence_results$coverage_probability
vectors <- convergence_results$vectors
critical_value <- convergence_results$critical_value
chi_squared_stats <- convergence_results$chi_squared_stats
# Calculate the critical radius
critical_radius <- sqrt(critical_value)
# Function to generate sphere coordinates
generate_sphere <- function(radius, n = 100) {
theta <- seq(0, 2 * pi, length.out = n)
phi <- seq(0, pi, length.out = n)
theta_grid <- rep(theta, each = length(phi))
phi_grid <- rep(phi, length(theta))
x <- radius * sin(phi_grid) * cos(theta_grid)
y <- radius * sin(phi_grid) * sin(theta_grid)
z <- radius * cos(phi_grid)
return(list(x = x, y = y, z = z))
}
# Generate sphere coordinates
sphere_coords <- generate_sphere(critical_radius)
# Create a 3D scatter plot with Plotly
fig <- plot_ly(x = vectors[,1], y = vectors[,2], z = vectors[,3],
type = 'scatter3d', mode = 'markers',
marker = list(color = ifelse(chi_squared_stats > critical_value, 'red', 'blue'),
size = 3)) %>%
add_trace(x = sphere_coords$x, y = sphere_coords$y, z = sphere_coords$z,
type = 'scatter3d', mode = 'markers',
marker = list(color = 'lightblue', size = 2, opacity = 0.3),
showlegend = FALSE) %>%
layout(scene = list(xaxis = list(title = 'Z1'),
yaxis = list(title = 'Z2'),
zaxis = list(title = 'Z3')))
# Show the plot
fig
# Save the alpha density plot as a PDF
pdf("scenario_plots/alpha_density_plot.pdf", width = 12, height = 7)
ggplot(results, aes(x = alpha)) +
geom_density(fill = "lightblue", color = "black", alpha = 0.7) +
geom_vline(xintercept = 3, color = "red", linetype = "dashed", size = 1) +
xlab(expression(hat(alpha))) + ylab("Density")
dev.off()
# Calculate the critical value for the given confidence level
z_alpha <- qnorm(1 - alpha_level / 2)
# Calculate the standard error
standard_error <- sqrt(alpha_level * (1 - alpha_level) / M)
# Compute the confidence interval
lower_bound <- (1 - alpha_level) - z_alpha * standard_error
upper_bound <- (1 - alpha_level) + z_alpha * standard_error
cat("Observed coverage probability:", coverage_probability, "\n")
cat("90% Confidence interval:", lower_bound, "-", upper_bound, "\n")
# Define the folder where the .rds files are stored
folder_name <- "rds_files"
# Initialize a list to store the inferred boundaries
boundary_estimates_list <- list()
# Get the list of all inferred boundary files in the folder
inferred_files <- list.files(folder_name, pattern = "inferred_boundary_.*\\.rds", full.names = TRUE)
# Loop through the files and read the inferred boundary estimates
for (file in inferred_files) {
inferred_results <- readRDS(file)
boundary_estimates_list[[file]] <- inferred_results$boundary_est
}
# Define the real boundary
real_boundary <- boundary_wrapper(c(alpha = 3, mu = 20, sigma2 = 2), partition_length = 100, strike = 19.5, expiration = 1)
# Define the timestep
timestep <- 0.01
# Calculate time points based on the timestep and length of the boundary estimates
time_points <- (0:(length(boundary_estimates_list[[1]]) - 1)) * timestep
# Define the output PDF filename
pdf_filename <- "plots/all_inferred_boundaries.pdf"
# Save the plot as a PDF with specified dimensions
pdf(file = pdf_filename, width = 10, height = 7)
plot(NULL, xlim = c(0, max(time_points)), ylim = range(sapply(boundary_estimates_list, range)),
xlab = "Time", ylab = "Value")
# Add each boundary estimate to the plot
for (boundary_estimate in boundary_estimates_list) {
lines(time_points, boundary_estimate, col = rgb(0, 0, 1, alpha = 0.1))
}
# Add the real boundary in red
lines(time_points, real_boundary, col = "red", lwd = 2)
# Close the PDF device
dev.off()
# Define the folder where the .rds files are stored
folder_name <- "rds_files"
# Initialize a list to store the inferred boundaries
boundary_estimates_list <- list()
# Get the list of all inferred boundary files in the folder
inferred_files <- list.files(folder_name, pattern = "inferred_boundary_.*\\.rds", full.names = TRUE)
# Loop through the files and read the inferred boundary estimates
for (file in inferred_files) {
inferred_results <- readRDS(file)
boundary_estimates_list[[file]] <- inferred_results$boundary_est
}
# Combine all inferred boundary estimates into a matrix for easier percentile computation
boundary_matrix <- do.call(rbind, boundary_estimates_list)
# Compute the 10th and 90th percentiles across all samples
percentile_10 <- apply(boundary_matrix, 2, function(x) quantile(x, 0.10))
percentile_90 <- apply(boundary_matrix, 2, function(x) quantile(x, 0.90))
# Define the real boundary
real_boundary <- boundary_wrapper(c(alpha = 3, mu = 20, sigma2 = 2), partition_length = 100, strike = 19.5, expiration = 1)
# Define the timestep and calculate time points
timestep <- 0.01
time_points <- (0:(length(real_boundary) - 1)) * timestep
# Define the output PDF filename
pdf_filename <- "plots/all_boundaries_density.pdf"
# Save the plot as a PDF with specified dimensions
pdf(file = pdf_filename, width = 10, height = 7)
plot(NULL, xlim = c(0, max(time_points)), ylim = range(c(percentile_10, percentile_90, real_boundary)),
xlab = "Time", ylab = "Value")
# Add shaded area between 10th and 90th percentiles
polygon(c(time_points, rev(time_points)),
c(percentile_10, rev(percentile_90)), col = rgb(0, 0, 1, alpha = 0.2), border = NA)
# Add the real boundary in red
lines(time_points, real_boundary, col = "red", lwd = 2)
# Close the PDF device
dev.off()
